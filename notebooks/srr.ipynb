{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Go to folder containing the source code\n",
    "cd /app/mialsuperresolutiontoolkit/\n",
    "# Install the pymialsrtk package inside the python/conda environment\n",
    "python setup.py install --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# Imports from nipype\n",
    "from nipype.interfaces.io import BIDSDataGrabber,DataGrabber, DataSink\n",
    "from nipype.pipeline import Node, Workflow\n",
    "\n",
    "# Import the implemented interface from pymialsrtk\n",
    "import pymialsrtk.interfaces.preprocess as preprocess\n",
    "import pymialsrtk.interfaces.reconstruction as reconstruction\n",
    "\n",
    "import pymialsrtk.interfaces.postprocess as postprocess\n",
    "\n",
    "# Cpoy result files\n",
    "from shutil import copyfile\n",
    "import glob\n",
    "\n",
    "from nipype import config, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set different variables (defined in cell 2) such that we do not have to rerun cell 2\n",
    "bids_dir = os.path.join('/fetaldata')\n",
    "\n",
    "subject = 'sub-01'\n",
    "session = None\n",
    "stacksOrder = [1,3,5,2,4,6]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "def run(command, env={}, cwd=os.getcwd()):\n",
    "    import subprocess\n",
    "    merged_env = os.environ\n",
    "    merged_env.update(env)\n",
    "    process = subprocess.run(command, shell=True,\n",
    "                             env=merged_env, cwd=cwd, capture_output=True)\n",
    "    return process\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# \n",
    "# Copy result files to BIDS\n",
    "def copy_results_to_bids(p_bids_dir, nipype_dir, p_wf_base_dir, p_stacksOrder, subject, session=None):\n",
    "\n",
    "    create_json_path = os.path.join(p_bids_dir, \"code\", \"create_scan_preproc_json.sh\")\n",
    "    if session is None:\n",
    "        t2w_dir = os.path.join(p_bids_dir, subject, \"anat\")\n",
    "        mask_dir = os.path.join(p_bids_dir, 'derivatives', 'manual_masks', subject, \"anat\")\n",
    "        \n",
    "        anat_dir = os.path.join(p_wf_base_dir, \"anat\")\n",
    "        if not os.path.exists(anat_dir):\n",
    "            os.makedirs(anat_dir)\n",
    "\n",
    "        xfm_dir = os.path.join(p_wf_base_dir, \"xfm\")\n",
    "        if not os.path.exists(xfm_dir):\n",
    "            os.makedirs(xfm_dir)\n",
    "    else:        \n",
    "        t2w_dir = os.path.join(bids_dir, subject, session, \"anat\")\n",
    "        mask_dir = os.path.join(bids_dir, 'derivatives', 'manual_masks', subject, session, \"anat\")\n",
    "\n",
    "        anat_dir = os.path.join(p_wf_base_dir, \"anat\")\n",
    "        if not os.path.exists(anat_dir):\n",
    "            os.makedirs(anat_dir)\n",
    "\n",
    "        xfm_dir = os.path.join(p_wf_base_dir, \"xfm\")\n",
    "        if not os.path.exists(xfm_dir):\n",
    "            os.makedirs(xfm_dir)\n",
    "\n",
    "    uni_bcorr_histnorm_dir = os.path.join(nipype_dir, \"srtkIntensityStandardization02\")\n",
    "    transform_nV_dir = os.path.join(nipype_dir, \"srtkImageReconstruction\")\n",
    "\n",
    "  \n",
    "    sources = \"\"\n",
    "    sources_lst = []\n",
    "    for num_stack in p_stacksOrder:\n",
    "        \n",
    "        \n",
    "        preproc_files = glob.glob(os.path.join(uni_bcorr_histnorm_dir, ''.join([\"*run-\",str(num_stack), \"_*T2w_uni_bcorr_histnorm.nii.gz\"])))[0]\n",
    "        dst_T2w = os.path.join(anat_dir, os.path.basename(preproc_files).replace(\"_uni_bcorr_histnorm\", \"_preproc\"))\n",
    "        copyfile(preproc_files, dst_T2w)\n",
    "\n",
    "        transform_files = glob.glob(os.path.join(transform_nV_dir, ''.join([\"*run-\",str(num_stack), \"_*T2w_nlm_uni_bcorr_histnorm_transform_*V.txt\"])))[0]\n",
    "        filename = os.path.basename(transform_files)\n",
    "        dst_transf = os.path.join(xfm_dir, filename.replace(filename[filename.find(\"_transform\"):], \"_from-orig_to-SDI_mode-image_xfm.txt\"))\n",
    "        copyfile(transform_files, dst_transf)\n",
    "\n",
    "        \n",
    "        init_mask = glob.glob(os.path.join(mask_dir, ''.join([\"*run-\", str(num_stack), \"*mask.nii.gz\" ])))[0]\n",
    "        copyfile(init_mask, os.path.join(anat_dir, os.path.basename(init_mask)))\n",
    "\n",
    "\n",
    "        sources += os.path.join(anat_dir, filename.replace(\"_uni_bcorr_histnorm\", \"_preproc\")) + \", \"\n",
    "        sources += os.path.join(xfm_dir, filename.replace(filename[filename.find(\"_transform\"):], \"_from-orig_to-SDI_mode-image_xfm.txt\")) + \", \"\n",
    "        sources += os.path.join(anat_dir, os.path.basename(init_mask)) + \", \"\n",
    "\n",
    "        sources_lst.append(os.path.join(anat_dir, filename.replace(\"_uni_bcorr_histnorm\", \"_preproc\")))\n",
    "        sources_lst.append(os.path.join(xfm_dir, filename.replace(filename[filename.find(\"_transform\"):], \"_from-orig_to-SDI_mode-image_xfm.txt\")))\n",
    "        sources_lst.append(os.path.join(anat_dir, os.path.basename(init_mask)))\n",
    "\n",
    "\n",
    "    sdi_dir = os.path.join(nipype_dir, \"srtkImageReconstruction\")\n",
    "    srtv_dir = os.path.join(nipype_dir, \"srtkN4BiasFieldCorrection\")\n",
    "    srtv_masked_dir = os.path.join(nipype_dir, \"srtkMaskImage02\")\n",
    "\n",
    "    print(\"Copy final outputs to ${ANAT_DIR}\")\n",
    "\n",
    "    # SDI \n",
    "    sdi_files = glob.glob(os.path.join(sdi_dir, ''.join([\"SDI_*.nii.gz\"])))[0]\n",
    "    filename = os.path.basename(sdi_files)\n",
    "    dst_sdi = '_'.join([filename.replace('SDI_', '').split(''.join(['_',str(len(p_stacksOrder)), \"V_\"]))[0], 'rec-SDI', 'T2w.nii.gz'])\n",
    "    copyfile(sdi_files, os.path.join(anat_dir, dst_sdi))\n",
    "    print(\"\")\n",
    "    print(sdi_files)\n",
    "    print(\"to\")\n",
    "    print(os.path.join(anat_dir, dst_sdi))\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "    # SRTV \n",
    "    srtv_files = glob.glob(os.path.join(srtv_dir, ''.join([\"SRTV_*_gbcorr.nii.gz\"])))[0]\n",
    "    filename = os.path.basename(srtv_files)\n",
    "    dst_srtv = '_'.join([filename.replace('SRTV_', '').split(''.join(['_',str(len(p_stacksOrder)), \"V_\"]))[0], 'rec-SR', 'T2w.nii.gz'])\n",
    "    copyfile(srtv_files, os.path.join(anat_dir, dst_srtv))\n",
    "    print(\"\")\n",
    "    print(srtv_files)\n",
    "    print(\"to\")\n",
    "    print(os.path.join(anat_dir, dst_srtv))\n",
    "    print(\"\")\n",
    "\n",
    "    # to do - masked SRTV/SDI ?  \n",
    "    srtv_masked_files = glob.glob(os.path.join(srtv_masked_dir, ''.join([\"SRTV_*.nii.gz\"])))[0]\n",
    "    filename = os.path.basename(srtv_masked_files)\n",
    "    dst_srtv = '_'.join([filename.replace('SRTV_', '').split(''.join(['_',str(len(p_stacksOrder)), \"V_\"]))[0], 'rec-SRmasked', 'T2w.nii.gz'])\n",
    "    copyfile(srtv_masked_files, os.path.join(anat_dir, dst_srtv))\n",
    "    print(\"\")\n",
    "    print(srtv_files)\n",
    "    print(\"to\")\n",
    "    print(os.path.join(anat_dir, dst_srtv))\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "    output_dict = {}\n",
    "\n",
    "    output_dict[\"Description\"] = \"Isotropic high-resolution image reconstructed using the Total-Variation Super-Resolution algorithm provided by MIALSRTK\"\n",
    "    # output_dict[\"Sources\"] = sources\n",
    "    output_dict[\"Sources\"] = sources_lst\n",
    "    output_dict[\"CustomMetaData\"] = {}\n",
    "    output_dict[\"CustomMetaData\"][\"Number of scans used\"] = str(len(p_stacksOrder))\n",
    "    output_dict[\"CustomMetaData\"][\"TV regularization weight lambda\"] = \"4\"\n",
    "    output_dict[\"CustomMetaData\"][\"Optimization time step\"] = \"3\"\n",
    "    output_dict[\"CustomMetaData\"][\"Primal/dual loops\"] = \"2\"\n",
    "    output_dict[\"CustomMetaData\"][\"Number of pipeline iterations\"] = \"1\"\n",
    "\n",
    "    output_json = os.path.join(anat_dir, ''.join([subject, '_rec-SR.json']))\n",
    "    with open(output_json, 'w+', encoding='utf8') as outfile:\n",
    "        json.dump(output_dict, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Node linkage\n",
    "def create_workflow(bids_dir, process_dir, subject, p_stacksOrder, session=None, deltatTV = 0.01, lambdaTV = 0.75, primal_dual_loops=10):\n",
    "#     wf_base_dir = os.path.join(\"{}\".format(output_dir),\"superres-mri\",\"sub-{}\".format(subject),\"nipype\")\n",
    "    \n",
    "    if session is None:\n",
    "        wf_base_dir = os.path.join(process_dir, subject)\n",
    "        process_dir = os.path.join(process_dir, subject)\n",
    "    else:\n",
    "        wf_base_dir = os.path.join(process_dir, subject, session)\n",
    "        process_dir = os.path.join(process_dir, subject, session)\n",
    "\n",
    "    if not os.path.exists(process_dir):\n",
    "        os.makedirs(process_dir)\n",
    "    print(\"Process directory: {}\".format(wf_base_dir))\n",
    "\n",
    "    wf = Workflow(name=\"srr_nipype\",base_dir=wf_base_dir)\n",
    "    srr_nipype_dir = os.path.join(wf.base_dir, wf.name )\n",
    "    \n",
    "    \n",
    "    # Initialization\n",
    "    if os.path.isfile(os.path.join(process_dir,\"pypeline_\"+subject+\".log\")):\n",
    "        os.unlink(os.path.join(process_dir,\"pypeline_\"+subject+\".log\"))\n",
    "#         open(os.path.join(process_dir,\"pypeline.log\"), 'a').close()\n",
    "        \n",
    "\n",
    "    config.update_config({'logging': {'log_directory': os.path.join(process_dir), 'log_to_file': True},\n",
    "                          'execution': {\n",
    "                              'remove_unnecessary_outputs': False,\n",
    "                              'stop_on_first_crash': True,\n",
    "                              'stop_on_first_rerun': False,\n",
    "                              'crashfile_format': \"txt\",\n",
    "                              'write_provenance' : False,},\n",
    "                          'monitoring': { 'enabled': True }\n",
    "                        })\n",
    "    \n",
    "    logging.update_logging(config)\n",
    "    iflogger = logging.getLogger('nipype.interface')\n",
    "\n",
    "    iflogger.info(\"**** Processing ****\")\n",
    "\n",
    "    \n",
    "    dg = Node(interface=DataGrabber(outfields = ['T2ws', 'masks']), name='data_grabber')\n",
    "    \n",
    "    dg.inputs.base_directory = bids_dir\n",
    "    dg.inputs.template = '*'\n",
    "    dg.inputs.raise_on_empty = False\n",
    "    dg.inputs.sort_filelist=True\n",
    "    \n",
    "    dg.inputs.field_template = dict(T2ws=os.path.join(subject, 'anat', subject+'*_run-*_T2w.nii.gz'),\n",
    "                                   masks=os.path.join('derivatives','manual_masks', subject, 'anat', subject+'*_run-*_*mask.nii.gz'))\n",
    "    if not (session is None):\n",
    "        dg.inputs.field_template = dict(T2ws=os.path.join( subject, session, 'anat', '_'.join([subject, session, '*run-*', '*T2w.nii.gz'])),\n",
    "                                        masks=os.path.join('derivatives','manual_masks', subject, session, 'anat','_'.join([subject, session, '*run-*', '*mask.nii.gz'])))\n",
    "    \n",
    "    \n",
    "        \n",
    "    nlmDenoise = Node(interface=preprocess.MultipleBtkNLMDenoising(), name='nlmDenoise')\n",
    "    nlmDenoise.inputs.bids_dir = bids_dir\n",
    "    nlmDenoise.inputs.stacksOrder = p_stacksOrder\n",
    "\n",
    "    \n",
    "    # Sans le mask le premier correct slice intensity...\n",
    "    srtkCorrectSliceIntensity01_nlm = Node(interface=preprocess.MultipleMialsrtkCorrectSliceIntensity(), name='srtkCorrectSliceIntensity01_nlm')\n",
    "    srtkCorrectSliceIntensity01_nlm.inputs.bids_dir = bids_dir\n",
    "    srtkCorrectSliceIntensity01_nlm.inputs.stacksOrder = p_stacksOrder\n",
    "    srtkCorrectSliceIntensity01_nlm.inputs.out_postfix = '_uni'\n",
    "\n",
    "    srtkCorrectSliceIntensity01 = Node(interface=preprocess.MultipleMialsrtkCorrectSliceIntensity(), name='srtkCorrectSliceIntensity01')\n",
    "    srtkCorrectSliceIntensity01.inputs.bids_dir = bids_dir\n",
    "    srtkCorrectSliceIntensity01.inputs.stacksOrder = p_stacksOrder\n",
    "    srtkCorrectSliceIntensity01.inputs.out_postfix = '_uni'\n",
    "\n",
    "    \n",
    "    \n",
    "    srtkSliceBySliceN4BiasFieldCorrection = Node(interface=preprocess.MultipleMialsrtkSliceBySliceN4BiasFieldCorrection(), name='srtkSliceBySliceN4BiasFieldCorrection')\n",
    "    srtkSliceBySliceN4BiasFieldCorrection.inputs.bids_dir = bids_dir\n",
    "    srtkSliceBySliceN4BiasFieldCorrection.inputs.stacksOrder = p_stacksOrder\n",
    "    \n",
    "    srtkSliceBySliceCorrectBiasField = Node(interface=preprocess.MultipleMialsrtkSliceBySliceCorrectBiasField(), name='srtkSliceBySliceCorrectBiasField')\n",
    "    srtkSliceBySliceCorrectBiasField.inputs.bids_dir = bids_dir\n",
    "    srtkSliceBySliceCorrectBiasField.inputs.stacksOrder = p_stacksOrder\n",
    "    \n",
    "    \n",
    "    \n",
    "    srtkCorrectSliceIntensity02_nlm = Node(interface=preprocess.MultipleMialsrtkCorrectSliceIntensity(), name='srtkCorrectSliceIntensity02_nlm')\n",
    "    srtkCorrectSliceIntensity02_nlm.inputs.bids_dir = bids_dir\n",
    "    srtkCorrectSliceIntensity02_nlm.inputs.stacksOrder = p_stacksOrder\n",
    "\n",
    "    srtkCorrectSliceIntensity02 = Node(interface=preprocess.MultipleMialsrtkCorrectSliceIntensity(), name='srtkCorrectSliceIntensity02')\n",
    "    srtkCorrectSliceIntensity02.inputs.bids_dir = bids_dir\n",
    "    srtkCorrectSliceIntensity02.inputs.stacksOrder = p_stacksOrder\n",
    "    \n",
    "    \n",
    "    srtkIntensityStandardization01 = Node(interface=preprocess.MialsrtkIntensityStandardization(), name='srtkIntensityStandardization01')\n",
    "    srtkIntensityStandardization01.inputs.bids_dir = bids_dir\n",
    "    \n",
    "    \n",
    "    srtkIntensityStandardization01_nlm = Node(interface=preprocess.MialsrtkIntensityStandardization(), name='srtkIntensityStandardization01_nlm')\n",
    "    srtkIntensityStandardization01_nlm.inputs.bids_dir = bids_dir\n",
    "    \n",
    "    \n",
    "    srtkHistogramNormalization = Node(interface=preprocess.MialsrtkHistogramNormalization(), name='srtkHistogramNormalization')\n",
    "    srtkHistogramNormalization.inputs.bids_dir = bids_dir\n",
    "    srtkHistogramNormalization.inputs.stacksOrder = p_stacksOrder\n",
    "    \n",
    "    srtkHistogramNormalization_nlm = Node(interface=preprocess.MialsrtkHistogramNormalization(), name='srtkHistogramNormalization_nlm')  \n",
    "    srtkHistogramNormalization_nlm.inputs.bids_dir = bids_dir\n",
    "    srtkHistogramNormalization_nlm.inputs.stacksOrder = p_stacksOrder\n",
    "    \n",
    "    \n",
    "    srtkIntensityStandardization02 = Node(interface=preprocess.MialsrtkIntensityStandardization(), name='srtkIntensityStandardization02')\n",
    "    srtkIntensityStandardization02.inputs.bids_dir = bids_dir\n",
    "    \n",
    "    \n",
    "    srtkIntensityStandardization02_nlm = Node(interface=preprocess.MialsrtkIntensityStandardization(), name='srtkIntensityStandardization02_nlm')\n",
    "    srtkIntensityStandardization02_nlm.inputs.bids_dir = bids_dir\n",
    "    \n",
    "    \n",
    "    srtkMaskImage01 = Node(interface=preprocess.MultipleMialsrtkMaskImage(), name='srtkMaskImage01')\n",
    "    srtkMaskImage01.inputs.bids_dir = bids_dir\n",
    "    srtkMaskImage01.inputs.stacksOrder = p_stacksOrder\n",
    "\n",
    "\n",
    "    srtkImageReconstruction = Node(interface=reconstruction.MialsrtkImageReconstruction(), name='srtkImageReconstruction')  \n",
    "    srtkImageReconstruction.inputs.bids_dir = bids_dir\n",
    "    srtkImageReconstruction.inputs.stacksOrder = p_stacksOrder \n",
    "\n",
    "    \n",
    "    sub_ses = subject\n",
    "    if session != None:\n",
    "        sub_ses = ''.join([sub_ses, '_', session])\n",
    "    srtkImageReconstruction.inputs.sub_ses = sub_ses\n",
    "    \n",
    "    srtkTVSuperResolution = Node(interface=reconstruction.MialsrtkTVSuperResolution(), name='srtkTVSuperResolution')  \n",
    "    srtkTVSuperResolution.inputs.bids_dir = bids_dir\n",
    "    srtkTVSuperResolution.inputs.stacksOrder = p_stacksOrder\n",
    "    srtkTVSuperResolution.inputs.sub_ses = sub_ses\n",
    "    srtkTVSuperResolution.inputs.in_loop = primal_dual_loops\n",
    "    srtkTVSuperResolution.inputs.in_deltat = deltatTV\n",
    "    srtkTVSuperResolution.inputs.in_lambda = lambdaTV\n",
    "    \n",
    "    \n",
    "\n",
    "    srtkRefineHRMaskByIntersection = Node(interface=postprocess.MialsrtkRefineHRMaskByIntersection(), name='srtkRefineHRMaskByIntersection')\n",
    "    srtkRefineHRMaskByIntersection.inputs.bids_dir = bids_dir\n",
    "    srtkRefineHRMaskByIntersection.inputs.stacksOrder = p_stacksOrder\n",
    "    \n",
    "    srtkN4BiasFieldCorrection = Node(interface=postprocess.MialsrtkN4BiasFieldCorrection(), name='srtkN4BiasFieldCorrection')\n",
    "    srtkN4BiasFieldCorrection.inputs.bids_dir = bids_dir\n",
    "    \n",
    "    \n",
    "    srtkMaskImage02 = Node(interface=preprocess.MialsrtkMaskImage(), name='srtkMaskImage02')\n",
    "    srtkMaskImage02.inputs.bids_dir = bids_dir\n",
    "    \n",
    "    datasink = Node(DataSink(), name='sinker')\n",
    "    output_dir = os.path.join(\"{}\".format(bids_dir),\"derivatives\",\"mialsrtk-py\")\n",
    "    datasink.inputs.base_directory = output_dir\n",
    "    \n",
    "    #\n",
    "    ## Nodes ready - Linking now\n",
    "    \n",
    "    wf.connect(dg, \"T2ws\", nlmDenoise, \"input_images\")\n",
    "#     wf.connect(dg, \"masks\", nlmDenoise, \"input_masks\")  ## Comment to match docker process\n",
    "    \n",
    "    wf.connect(nlmDenoise, \"output_images\", srtkCorrectSliceIntensity01_nlm, \"input_images\")\n",
    "    wf.connect(dg, \"masks\", srtkCorrectSliceIntensity01_nlm, \"input_masks\")\n",
    "    \n",
    "    wf.connect(dg, \"T2ws\", srtkCorrectSliceIntensity01, \"input_images\")\n",
    "    wf.connect(dg, \"masks\", srtkCorrectSliceIntensity01, \"input_masks\")\n",
    "    \n",
    "    wf.connect(srtkCorrectSliceIntensity01_nlm, \"output_images\", srtkSliceBySliceN4BiasFieldCorrection, \"input_images\")\n",
    "    wf.connect(dg, \"masks\", srtkSliceBySliceN4BiasFieldCorrection, \"input_masks\")\n",
    "    \n",
    "    wf.connect(srtkCorrectSliceIntensity01, \"output_images\", srtkSliceBySliceCorrectBiasField, \"input_images\")\n",
    "    wf.connect(srtkSliceBySliceN4BiasFieldCorrection, \"output_fields\", srtkSliceBySliceCorrectBiasField, \"input_fields\")\n",
    "    wf.connect(dg, \"masks\", srtkSliceBySliceCorrectBiasField, \"input_masks\")\n",
    "    \n",
    "    wf.connect(srtkSliceBySliceCorrectBiasField, \"output_images\", srtkCorrectSliceIntensity02, \"input_images\")\n",
    "    wf.connect(dg, \"masks\", srtkCorrectSliceIntensity02, \"input_masks\")\n",
    "    \n",
    "    wf.connect(srtkSliceBySliceN4BiasFieldCorrection, \"output_images\", srtkCorrectSliceIntensity02_nlm, \"input_images\")\n",
    "    wf.connect(dg, \"masks\", srtkCorrectSliceIntensity02_nlm, \"input_masks\")\n",
    "    \n",
    "    wf.connect(srtkCorrectSliceIntensity02, \"output_images\", srtkIntensityStandardization01, \"input_images\")\n",
    "    \n",
    "    wf.connect(srtkCorrectSliceIntensity02_nlm, \"output_images\", srtkIntensityStandardization01_nlm, \"input_images\")\n",
    "    \n",
    "    wf.connect(srtkIntensityStandardization01, \"output_images\", srtkHistogramNormalization, \"input_images\")\n",
    "    wf.connect(dg, \"masks\", srtkHistogramNormalization, \"input_masks\")\n",
    "    \n",
    "    wf.connect(srtkIntensityStandardization01_nlm, \"output_images\", srtkHistogramNormalization_nlm, \"input_images\")\n",
    "    wf.connect(dg, \"masks\", srtkHistogramNormalization_nlm, \"input_masks\")\n",
    "    \n",
    "    wf.connect(srtkHistogramNormalization, \"output_images\", srtkIntensityStandardization02, \"input_images\")\n",
    "    \n",
    "    wf.connect(srtkHistogramNormalization_nlm, \"output_images\", srtkIntensityStandardization02_nlm, \"input_images\")\n",
    "    \n",
    "    \n",
    "    wf.connect(srtkIntensityStandardization02_nlm, \"output_images\", srtkMaskImage01, \"input_images\")\n",
    "    wf.connect(dg, \"masks\", srtkMaskImage01, \"input_masks\")\n",
    "    \n",
    "    \n",
    "    wf.connect(srtkMaskImage01, \"output_images\", srtkImageReconstruction, \"input_images\")\n",
    "    wf.connect(dg, \"masks\", srtkImageReconstruction, \"input_masks\")\n",
    "    \n",
    "    wf.connect(srtkIntensityStandardization02, \"output_images\", srtkTVSuperResolution, \"input_images\")\n",
    "    wf.connect(srtkImageReconstruction, \"output_transforms\", srtkTVSuperResolution, \"input_transforms\")\n",
    "    wf.connect(dg, \"masks\", srtkTVSuperResolution, \"input_masks\")\n",
    "    wf.connect(srtkImageReconstruction, \"output_sdi\", srtkTVSuperResolution, \"input_sdi\")\n",
    "    \n",
    "    \n",
    "    wf.connect(srtkIntensityStandardization02, \"output_images\", srtkRefineHRMaskByIntersection, \"input_images\")\n",
    "    wf.connect(dg, \"masks\", srtkRefineHRMaskByIntersection, \"input_masks\")\n",
    "    wf.connect(srtkImageReconstruction, \"output_transforms\", srtkRefineHRMaskByIntersection, \"input_transforms\")\n",
    "    wf.connect(srtkTVSuperResolution, \"output_sr\", srtkRefineHRMaskByIntersection, \"input_sr\")\n",
    "    \n",
    "    wf.connect(srtkTVSuperResolution, \"output_sr\", srtkN4BiasFieldCorrection, \"input_image\")\n",
    "    wf.connect(srtkRefineHRMaskByIntersection, \"output_SRmask\", srtkN4BiasFieldCorrection, \"input_mask\")\n",
    "    \n",
    "    wf.connect(srtkTVSuperResolution, \"output_sr\", srtkMaskImage02, \"in_file\")\n",
    "    wf.connect(srtkRefineHRMaskByIntersection, \"output_SRmask\", srtkMaskImage02, \"in_mask\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #\n",
    "    ### - Saving files\n",
    "    \n",
    "    \n",
    "    substitutions = []\n",
    "    for stack in stacksOrder:\n",
    "    \n",
    "        print( sub_ses+'_run-'+str(stack)+'_T2w_nlm_uni_bcorr_histnorm.nii.gz', '    --->     ',sub_ses+'_run-'+str(stack)+'_T2w_preproc.nii.gz')\n",
    "        substitutions.append( ( sub_ses+'_run-'+str(stack)+'_T2w_nlm_uni_bcorr_histnorm.nii.gz', sub_ses+'_run-'+str(stack)+'_T2w_preproc.nii.gz') )\n",
    "        \n",
    "        print( sub_ses+'_run-'+str(stack)+'_T2w_nlm_uni_bcorr_histnorm_transform_'+str(len(stacksOrder))+'V.txt', '    --->     ', sub_ses+'_run-'+str(stack)+'_T2w_from-origin_to-SDI_mode-image_xfm.txt')\n",
    "        substitutions.append( ( sub_ses+'_run-'+str(stack)+'_T2w_nlm_uni_bcorr_histnorm_transform_'+str(len(stacksOrder))+'V.txt', sub_ses+'_run-'+str(stack)+'_T2w_from-origin_to-SDI_mode-image_xfm.txt') )\n",
    "        \n",
    "        print( sub_ses+'_run-'+str(stack)+'_T2w_uni_bcorr_histnorm_LRmask.nii.gz', '    --->     ', sub_ses+'_run-'+str(stack)+'_T2w_desc-LRmask.nii.gz')\n",
    "        substitutions.append( ( sub_ses+'_run-'+str(stack)+'_T2w_uni_bcorr_histnorm_LRmask.nii.gz', sub_ses+'_run-'+str(stack)+'_T2w_desc-LRmask.nii.gz') )\n",
    "\n",
    "        \n",
    "    print( 'SDI_'+sub_ses+'_'+str(len(stacksOrder))+'V_rad1.nii.gz', '    --->     ', sub_ses+'_rec-SDI_T2w.nii.gz')\n",
    "    substitutions.append( ( 'SDI_'+sub_ses+'_'+str(len(stacksOrder))+'V_rad1.nii.gz', sub_ses+'_rec-SDI_T2w.nii.gz') )\n",
    "\n",
    "    print( 'SRTV_'+sub_ses+'_'+str(len(stacksOrder))+'V_rad1_gbcorr.nii.gz', '    --->     ', sub_ses+'_rec-SR_T2w.nii.gz')\n",
    "    substitutions.append( ( 'SRTV_'+sub_ses+'_'+str(len(stacksOrder))+'V_rad1_gbcorr.nii.gz', sub_ses+'_rec-SR_T2w.nii.gz') )\n",
    "    \n",
    "\n",
    "    print( sub_ses+'_T2w_uni_bcorr_histnorm_srMask.nii.gz', '    --->     ', sub_ses+'_rec-SR_T2w_desc-brain_mask.nii.gz')\n",
    "    substitutions.append( ( sub_ses+'_T2w_uni_bcorr_histnorm_srMask.nii.gz', sub_ses+'_rec-SR_T2w_desc-SRmask.nii.gz') )\n",
    "\n",
    "    \n",
    "        \n",
    "    datasink.inputs.substitutions = substitutions\n",
    "    \n",
    "    wf.connect(srtkMaskImage01, \"output_images\", datasink, 'preproc')\n",
    "    wf.connect(srtkImageReconstruction, \"output_transforms\", datasink, 'xfm')\n",
    "    wf.connect(srtkRefineHRMaskByIntersection, \"output_LRmasks\", datasink, 'postproc')\n",
    "    \n",
    "    wf.connect(srtkImageReconstruction, \"output_sdi\", datasink, 'anat')\n",
    "    wf.connect(srtkN4BiasFieldCorrection, \"output_image\", datasink, 'anat.@SR')\n",
    "    wf.connect(srtkRefineHRMaskByIntersection, \"output_SRmask\", datasink, 'postproc.@SRmask')\n",
    "    \n",
    "    \n",
    "    # JSON file SRTV\n",
    "    output_dict = {}\n",
    "\n",
    "    output_dict[\"Description\"] = \"Isotropic high-resolution image reconstructed using the Total-Variation Super-Resolution algorithm provided by MIALSRTK\"\n",
    "    # output_dict[\"Sources\"] = sources\n",
    "    output_dict[\"Input sources run order\"] = stacksOrder\n",
    "    output_dict[\"CustomMetaData\"] = {}\n",
    "    output_dict[\"CustomMetaData\"][\"Number of scans used\"] = str(len(p_stacksOrder))\n",
    "    output_dict[\"CustomMetaData\"][\"TV regularization weight lambda\"] = lambdaTV\n",
    "    output_dict[\"CustomMetaData\"][\"Optimization time step\"] = deltatTV\n",
    "    output_dict[\"CustomMetaData\"][\"Primal/dual loops\"] = primal_dual_loops\n",
    "\n",
    "    output_json = os.path.join(output_dir, 'anat', ''.join([subject, '_rec-SR.json']))\n",
    "    with open(output_json, 'w+', encoding='utf8') as outfile:\n",
    "        json.dump(output_dict, outfile, indent=4)\n",
    "        \n",
    "    return wf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash\n",
    "\n",
    "\n",
    "python srr.py /fetaldata /fetaldata/output participant --participant_label \"HK01\" \"ctrl0022\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_wf = create_workflow(bids_dir, process_dir='/fetaldata/derivatives/tmp_proc', subject=subject, p_stacksOrder=stacksOrder, session = session)\n",
    "m_wf.write_graph()\n",
    "aa = m_wf.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
