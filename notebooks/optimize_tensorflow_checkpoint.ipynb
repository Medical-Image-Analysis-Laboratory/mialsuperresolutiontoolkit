{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for optimizing brain extraction tensorflow models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/miniconda3/envs/pymialsrtk-env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import data\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python import ops\n",
    "from tensorflow.tools.graph_transforms import TransformGraph\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d, upsample_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions that optimized tensorflow SavedModel\n",
    "Taken from https://medium.com/google-cloud/optimizing-tensorflow-models-for-serving-959080e9ddbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and convert the SavedModel into a GraphDef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit_dir = '/Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit'\n",
    "image = f'{toolkit_dir}/data/sub-01/anat/sub-01_run-1_T2w.nii.gz'\n",
    "manual_mask = f'{toolkit_dir}/data/derivatives/manual_masks/sub-01/anat/sub-01_run-1_desc-brain_mask.nii.gz'\n",
    "modelCkptLoc = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization/Unet.ckpt-88000'\n",
    "modelCkptSeg = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation/Unet.ckpt-20000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run original brain mask extraction interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201205-08:51:26,737 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"brainmask_wf_node\" in \"/Users/sebastientourbier/Desktop/mialsrtk/brainmask_wf_node\".\n",
      "201205-08:51:26,741 nipype.workflow INFO:\n",
      "\t [Node] Cached \"brainmask_wf_node\" - collecting precomputed outputs\n",
      "201205-08:51:26,741 nipype.workflow INFO:\n",
      "\t [Node] \"brainmask_wf_node\" found cached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nipype.interfaces.base.support.InterfaceResult at 0x7fc5bf665320>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nipype import Node\n",
    "from pymialsrtk.interfaces.preprocess import BrainExtraction\n",
    "brainmask = Node(interface=BrainExtraction(), name='brainmask_wf_node', base_dir = '/Users/sebastientourbier/Desktop/mialsrtk')\n",
    "brainmask.inputs.bids_dir = f'{toolkit_dir}/data'\n",
    "brainmask.inputs.in_file = image\n",
    "brainmask.inputs.in_ckpt_loc = modelCkptLoc#+'v2'\n",
    "brainmask.inputs.threshold_loc = 0.49\n",
    "brainmask.inputs.in_ckpt_seg = modelCkptSeg#+'v2'\n",
    "brainmask.inputs.threshold_seg = 0.5\n",
    "brainmask.inputs.out_postfix = '_brainMask.nii.gz'\n",
    "brainmask.run() # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resave the graph with checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to create the tensorflow graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = \"local_max\"\n",
    "width = 128\n",
    "height = 128\n",
    "border_x = 15\n",
    "border_y = 15\n",
    "n_channels = 1\n",
    "\n",
    "# Tensorflow graph\n",
    "def create_graph():\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "\n",
    "        with tf.name_scope('inputs'):\n",
    "            x = tf.placeholder(tf.float32, [None, width, height, n_channels], name='image')\n",
    "            print(x)\n",
    "        conv1 = conv_2d(x, 32, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "        conv1 = conv_2d(conv1, 32, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "        pool1 = max_pool_2d(conv1, 2)\n",
    "\n",
    "        conv2 = conv_2d(pool1, 64, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "        conv2 = conv_2d(conv2, 64, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "        pool2 = max_pool_2d(conv2, 2)\n",
    "\n",
    "        conv3 = conv_2d(pool2, 128, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "        conv3 = conv_2d(conv3, 128, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "        pool3 = max_pool_2d(conv3, 2)\n",
    "\n",
    "        conv4 = conv_2d(pool3, 256, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "        conv4 = conv_2d(conv4, 256, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "        pool4 = max_pool_2d(conv4, 2)\n",
    "\n",
    "        conv5 = conv_2d(pool4, 512, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "        conv5 = conv_2d(conv5, 512, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "\n",
    "        up6 = upsample_2d(conv5, 2)\n",
    "        up6 = tflearn.layers.merge_ops.merge([up6, conv4], 'concat', axis=3)\n",
    "        conv6 = conv_2d(up6, 256, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "        conv6 = conv_2d(conv6, 256, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "\n",
    "        up7 = upsample_2d(conv6, 2)\n",
    "        up7 = tflearn.layers.merge_ops.merge([up7, conv3], 'concat', axis=3)\n",
    "        conv7 = conv_2d(up7, 128, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "        conv7 = conv_2d(conv7, 128, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "\n",
    "        up8 = upsample_2d(conv7, 2)\n",
    "        up8 = tflearn.layers.merge_ops.merge([up8, conv2], 'concat', axis=3)\n",
    "        conv8 = conv_2d(up8, 64, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "        conv8 = conv_2d(conv8, 64, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "\n",
    "        up9 = upsample_2d(conv8, 2)\n",
    "        up9 = tflearn.layers.merge_ops.merge([up9, conv1], 'concat', axis=3)\n",
    "        conv9 = conv_2d(up9, 32, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "        conv9 = conv_2d(conv9, 32, 3, activation='relu', padding='same', regularizer=\"L2\")\n",
    "\n",
    "        pred = conv_2d(conv9, 2, 1,  activation='linear', padding='valid')\n",
    "        #tf.identity(pred, name='prediction')\n",
    "        print(pred)\n",
    "    return g, x, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1 - `tf.train.Saver.save()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"inputs/image:0\", shape=(?, 128, 128, 1), dtype=float32)\n",
      "Tensor(\"Conv2D_18/BiasAdd:0\", shape=(?, 128, 128, 2), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization/Unet.ckpt-88000\n",
      "model saved in /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization/Unet.ckpt-88000v2\n",
      "Tensor(\"inputs/image:0\", shape=(?, 128, 128, 1), dtype=float32)\n",
      "Tensor(\"Conv2D_18/BiasAdd:0\", shape=(?, 128, 128, 2), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation/Unet.ckpt-20000\n",
      "model saved in /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation/Unet.ckpt-20000v2\n"
     ]
    }
   ],
   "source": [
    "normalize = \"local_max\"\n",
    "width = 128\n",
    "height = 128\n",
    "border_x = 15\n",
    "border_y = 15\n",
    "n_channels = 1\n",
    "\n",
    "# Tensorflow graph\n",
    "g, x, pred = create_graph()\n",
    "\n",
    "with tf.Session(graph=g) as sess_test_loc:\n",
    "    # Restore the model\n",
    "    tf_saver = tf.train.Saver()\n",
    "    tf_saver.restore(sess_test_loc, modelCkptLoc)\n",
    "    # save the model\n",
    "    saved_path = tf_saver.save(sess_test_loc, ''.join([modelCkptLoc,'v2']))\n",
    "    print('model saved in {}'.format(saved_path))\n",
    "\n",
    "# Tensorflow graph\n",
    "g, x, pred = create_graph()\n",
    "\n",
    "with tf.Session(graph=g) as sess_test_seg:\n",
    "    # Restore the model\n",
    "    tf_saver = tf.train.Saver()\n",
    "    tf_saver.restore(sess_test_seg, modelCkptSeg)\n",
    "    saved_path = tf_saver.save(sess_test_seg, ''.join([modelCkptSeg,'v2']))\n",
    "    print('model saved in {}'.format(saved_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2 - `tf.saved_model.simple_save()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"inputs/image:0\", shape=(?, 128, 128, 1), dtype=float32)\n",
      "Tensor(\"Conv2D_18/BiasAdd:0\", shape=(?, 128, 128, 2), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization/Unet.ckpt-88000\n",
      "WARNING:tensorflow:From <ipython-input-6-1551e304bd32>:23: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
      "WARNING:tensorflow:From /Applications/miniconda3/envs/pymialsrtk-env/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization2/saved_model.pb\n",
      "model saved in None\n",
      "INFO:tensorflow:Restoring parameters from /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation/Unet.ckpt-20000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation2/saved_model.pb\n",
      "model saved in None\n"
     ]
    }
   ],
   "source": [
    "normalize = \"local_max\"\n",
    "width = 128\n",
    "height = 128\n",
    "border_x = 15\n",
    "border_y = 15\n",
    "n_channels = 1\n",
    "\n",
    "# Tensorflow graph\n",
    "g, x, pred = create_graph()\n",
    "\n",
    "im = np.zeros((1, width, height, n_channels))\n",
    "pred3d = []\n",
    "with tf.Session(graph=g) as sess_test_loc:\n",
    "    # Restore the model\n",
    "    tf_saver = tf.train.Saver()\n",
    "    tf_saver.restore(sess_test_loc, modelCkptLoc)\n",
    "    # save the model\n",
    "    export_dir = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization2/'\n",
    "    saved_path = tf.saved_model.simple_save(\n",
    "        sess_test_loc,\n",
    "        export_dir,\n",
    "        inputs={\"inputs/image\": x},\n",
    "        outputs={\"Conv2D_18/BiasAdd\": pred})\n",
    "    \n",
    "    print('model saved in {}'.format(saved_path))\n",
    "    \n",
    "with tf.Session(graph=g) as sess_test_seg:\n",
    "    # Restore the model\n",
    "    tf_saver = tf.train.Saver()\n",
    "    tf_saver.restore(sess_test_seg, modelCkptSeg)\n",
    "    # save the model\n",
    "    export_dir = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation2/'\n",
    "    saved_path = tf.saved_model.simple_save(sess_test_seg,\n",
    "                               export_dir,\n",
    "                               inputs={\"inputs/image\": x},\n",
    "                               outputs={\"Conv2D_18/BiasAdd\": pred})\n",
    "    print('model saved in {}'.format(saved_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3 - `tf.saved_model.builder.SavedModelBuilder()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"inputs/image:0\", shape=(?, 128, 128, 1), dtype=float32)\n",
      "Tensor(\"Conv2D_18/BiasAdd:0\", shape=(?, 128, 128, 2), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization/Unet.ckpt-88000\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization3/saved_model.pb\n",
      "model saved in b'/Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization3/saved_model.pb'\n",
      "INFO:tensorflow:Restoring parameters from /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation/Unet.ckpt-20000\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation3/saved_model.pb\n",
      "model saved in b'/Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation3/saved_model.pb'\n"
     ]
    }
   ],
   "source": [
    "normalize = \"local_max\"\n",
    "width = 128\n",
    "height = 128\n",
    "border_x = 15\n",
    "border_y = 15\n",
    "n_channels = 1\n",
    "\n",
    "# Tensorflow graph\n",
    "g, x, pred = create_graph()\n",
    "\n",
    "im = np.zeros((1, width, height, n_channels))\n",
    "pred3d = []\n",
    "with tf.Session(graph=g) as sess_test_loc:\n",
    "    # Restore the model\n",
    "    tf_saver = tf.train.Saver()\n",
    "    tf_saver.restore(sess_test_loc, modelCkptLoc)\n",
    "    \n",
    "    # save the model\n",
    "    export_dir = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization3/'\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "\n",
    "    tensor_info_x = tf.saved_model.utils.build_tensor_info(x)\n",
    "    tensor_info_pred = tf.saved_model.utils.build_tensor_info(pred)\n",
    "\n",
    "    prediction_signature = (\n",
    "      tf.saved_model.signature_def_utils.build_signature_def(\n",
    "          inputs={'inputs/image': tensor_info_x},\n",
    "          outputs={'Conv2D_18/BiasAdd': tensor_info_pred},\n",
    "          method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))#\n",
    "\n",
    "    builder.add_meta_graph_and_variables(\n",
    "        sess_test_loc,\n",
    "        tags=[tf.saved_model.tag_constants.SERVING],\n",
    "        signature_def_map={\n",
    "            tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: prediction_signature },\n",
    "      )\n",
    "    saved_path = builder.save()\n",
    "    print('model saved in {}'.format(saved_path))\n",
    "    \n",
    "with tf.Session(graph=g) as sess_test_seg:\n",
    "    # Restore the model\n",
    "    tf_saver = tf.train.Saver()\n",
    "    tf_saver.restore(sess_test_seg, modelCkptSeg)\n",
    "    \n",
    "    # save the model\n",
    "    export_dir = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation3/'\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "\n",
    "    tensor_info_x = tf.saved_model.utils.build_tensor_info(x)\n",
    "    tensor_info_pred = tf.saved_model.utils.build_tensor_info(pred)\n",
    "\n",
    "    prediction_signature = (\n",
    "      tf.saved_model.signature_def_utils.build_signature_def(\n",
    "          inputs={'inputs/image': tensor_info_x},\n",
    "          outputs={'Conv2D_18/BiasAdd': tensor_info_pred},\n",
    "          method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "    builder.add_meta_graph_and_variables(\n",
    "        sess_test_seg,\n",
    "        tags=[tf.saved_model.tag_constants.SERVING],\n",
    "        signature_def_map={\n",
    "            tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: prediction_signature},\n",
    "        )\n",
    "    saved_path = builder.save()\n",
    "    print('model saved in {}'.format(saved_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize localization graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and convert the SavedModel into a GraphDef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-44f4939257e8>:6: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization3/variables/variables\n"
     ]
    }
   ],
   "source": [
    "def get_graph_def_from_saved_model(saved_model_dir): \n",
    "    with tf.Session() as session:\n",
    "        meta_graph_def = tf.saved_model.loader.load(\n",
    "        session,\n",
    "        tags=[tag_constants.SERVING],\n",
    "        export_dir=saved_model_dir\n",
    "        ) \n",
    "    return meta_graph_def.graph_def\n",
    "\n",
    "graph_def = get_graph_def_from_saved_model('/Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show graph description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Feature Nodes: ['inputs/image']\n",
      "\n",
      "Unused Nodes: []\n",
      "\n",
      "Output Nodes: ['Conv2D_18/BiasAdd']\n",
      "\n",
      "Quantization Nodes: []\n",
      "\n",
      "Constant Count: 119\n",
      "\n",
      "Variable Count: 38\n",
      "\n",
      "Identity Count: 41\n",
      " Total nodes: 512 \n"
     ]
    }
   ],
   "source": [
    "def describe_graph(graph_def, show_nodes=False):\n",
    "    print('Input Feature Nodes: {}'.format(\n",
    "        [node.name for node in graph_def.node if node.op=='Placeholder']))\n",
    "    print('')\n",
    "    print('Unused Nodes: {}'.format(\n",
    "        [node.name for node in graph_def.node if 'unused'  in node.name]))\n",
    "    print('')\n",
    "    print('Output Nodes: {}'.format( \n",
    "        [node.name for node in graph_def.node if (\n",
    "            'Conv2D_18/BiasAdd' in node.name or 'softmax' in node.name)]))\n",
    "    print('')\n",
    "    print('Quantization Nodes: {}'.format(\n",
    "        [node.name for node in graph_def.node if 'quant' in node.name]))\n",
    "    print('')\n",
    "    print('Constant Count: {}'.format(\n",
    "        len([node for node in graph_def.node if node.op=='Const'])))\n",
    "    print('')\n",
    "    print('Variable Count: {}'.format(\n",
    "      len([node for node in graph_def.node if 'Variable' in node.op])))\n",
    "    print('')\n",
    "    print('Identity Count: {}'.format(\n",
    "      len([node for node in graph_def.node if node.op=='Identity'])))\n",
    "    print('', 'Total nodes: {}'.format(len(graph_def.node)), '')\n",
    "\n",
    "    if show_nodes==True:\n",
    "        for node in graph_def.node:\n",
    "            print('Op:{} - Name: {}'.format(node.op, node.name))\n",
    "\n",
    "describe_graph(graph_def, show_nodes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization3/saved_model.pb \n",
      "Model size: 103.242 KB\n",
      "Variables size: 30650.242 KB\n",
      "Total Size: 30753.484 KB\n"
     ]
    }
   ],
   "source": [
    "def get_size(model_dir, model_file='saved_model.pb'):\n",
    "    model_file_path = os.path.join(model_dir, model_file)\n",
    "    print(model_file_path, '')\n",
    "    pb_size = os.path.getsize(model_file_path)\n",
    "    variables_size = 0\n",
    "    if os.path.exists(os.path.join(model_dir,'variables/variables.data-00000-of-00001')):\n",
    "        variables_size = os.path.getsize(os.path.join(\n",
    "            model_dir,'variables/variables.data-00000-of-00001'))\n",
    "        variables_size += os.path.getsize(os.path.join(\n",
    "            model_dir,'variables/variables.index'))\n",
    "    print('Model size: {} KB'.format(round(pb_size/(1024.0),3)))\n",
    "    print('Variables size: {} KB'.format(round( variables_size/(1024.0),3)))\n",
    "    print('Total Size: {} KB'.format(round((pb_size + variables_size)/(1024.0),3)))\n",
    "\n",
    "get_size(f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization3',\n",
    "         model_file='saved_model.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] input_checkpoint: /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization/Unet.ckpt-88000\n",
      "INFO:tensorflow:Restoring parameters from /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization/Unet.ckpt-88000\n",
      "INFO:tensorflow:Froze 38 variables.\n",
      "INFO:tensorflow:Converted 38 variables to const ops.\n",
      "161 ops in the final graph.\n",
      "[INFO] output_graph: /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization/frozen_model.pb\n",
      "[INFO] all done\n",
      "Input Feature Nodes: ['inputs/image']\n",
      "\n",
      "Unused Nodes: []\n",
      "\n",
      "Output Nodes: ['Conv2D_18/BiasAdd']\n",
      "\n",
      "Quantization Nodes: []\n",
      "\n",
      "Constant Count: 50\n",
      "\n",
      "Variable Count: 0\n",
      "\n",
      "Identity Count: 38\n",
      " Total nodes: 161 \n"
     ]
    }
   ],
   "source": [
    "def get_graph_def_from_file(graph_filepath):\n",
    "    with ops.Graph().as_default():\n",
    "        with tf.gfile.GFile(graph_filepath, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            return graph_def\n",
    "\n",
    "def freeze_model(saved_model_dir, output_node_names, output_filename, checkpoints):\n",
    "    \n",
    "    output_graph_filename = os.path.join(saved_model_dir, output_filename)\n",
    "    initializer_nodes = ''\n",
    "    freeze_graph.freeze_graph(\n",
    "        input_saved_model_dir=saved_model_dir,\n",
    "        output_graph=output_graph_filename,\n",
    "        saved_model_tags = tag_constants.SERVING,\n",
    "        output_node_names=output_node_names,\n",
    "        initializer_nodes=initializer_nodes,\n",
    "        input_graph=None,\n",
    "        input_saver=False,\n",
    "        input_binary=False,\n",
    "        input_checkpoint=checkpoints,\n",
    "        restore_op_name=None,\n",
    "        filename_tensor_name=None,\n",
    "        clear_devices=False,\n",
    "        input_meta_graph=False,\n",
    "    )\n",
    "    print('graph freezed!')\n",
    "    \n",
    "def freeze_model2(input_checkpoint,output_graph=\"frozen_model.pb\"):\n",
    "    from tensorflow.python.framework import graph_util\n",
    "    \n",
    "    print(\"[INFO] input_checkpoint:\", input_checkpoint)\n",
    "    \n",
    "    # Before exporting our graph, we need to precise what is our output node\n",
    "    # This is how TF decides what part of the Graph he has to keep and what part it can dump\n",
    "    output_node_names = \"Conv2D_18/BiasAdd\" # NOTE: Change here\n",
    "\n",
    "    # We clear devices to allow TensorFlow to control on which device it will load operations\n",
    "    clear_devices = True\n",
    "    \n",
    "    # We import the meta graph and retrieve a Saver\n",
    "    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n",
    "\n",
    "    # We retrieve the protobuf graph definition\n",
    "    graph = tf.get_default_graph()\n",
    "    input_graph_def = graph.as_graph_def()\n",
    "\n",
    "    # We start a session and restore the graph weights\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "\n",
    "        # We use a built-in TF helper to export variables to constants\n",
    "        output_graph_def = graph_util.convert_variables_to_constants(\n",
    "            sess,                        # The session is used to retrieve the weights\n",
    "            input_graph_def,             # The graph_def is used to retrieve the nodes \n",
    "            output_node_names.split(\",\") # The output node names are used to select the usefull nodes\n",
    "        ) \n",
    "\n",
    "        # Finally we serialize and dump the output graph to the filesystem\n",
    "        with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n",
    "\n",
    "        print(\"[INFO] output_graph:\",output_graph)\n",
    "        print(\"[INFO] all done\")\n",
    "\n",
    "saved_model_dir = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization3'\n",
    "frozen_model_dir = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization3'\n",
    "saved_model_dir = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization'\n",
    "frozen_model_dir = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization'\n",
    "frozen_filepath = os.path.join(frozen_model_dir, 'frozen_model.pb')\n",
    "#freeze_model(saved_model_dir, 'Conv2D_18/BiasAdd', frozen_filepath, modelCkptLoc)\n",
    "freeze_model2(modelCkptLoc, frozen_filepath)\n",
    "#frozen_filepath = os.path.join(saved_model_dir,'frozen_model.pb')\n",
    "#get_size(frozen_filepath)\n",
    "describe_graph(get_graph_def_from_file(frozen_filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization : pruning, constant folding and quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph optimized!\n",
      "Input Feature Nodes: ['inputs/image']\n",
      "\n",
      "Unused Nodes: []\n",
      "\n",
      "Output Nodes: ['Conv2D_18/BiasAdd']\n",
      "\n",
      "Quantization Nodes: []\n",
      "\n",
      "Constant Count: 44\n",
      "\n",
      "Variable Count: 0\n",
      "\n",
      "Identity Count: 0\n",
      " Total nodes: 117 \n"
     ]
    }
   ],
   "source": [
    "def get_graph_def_from_file(graph_filepath):\n",
    "    with ops.Graph().as_default():\n",
    "        with tf.gfile.GFile(graph_filepath, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            return graph_def\n",
    "\n",
    "def optimize_graph(model_dir, graph_filename, transforms, output_node):\n",
    "    input_names = []\n",
    "    output_names = [output_node]\n",
    "    if graph_filename is None:\n",
    "        graph_def = get_graph_def_from_saved_model(model_dir)\n",
    "    else:\n",
    "        graph_def = get_graph_def_from_file(os.path.join(model_dir, graph_filename))\n",
    "    optimized_graph_def = TransformGraph(graph_def,\n",
    "                                         input_names,\n",
    "                                         output_names,\n",
    "                                         transforms)\n",
    "    tf.train.write_graph(optimized_graph_def,\n",
    "                         logdir=model_dir,\n",
    "                         as_text=False,\n",
    "                         name='optimized_model.pb')\n",
    "    print('Graph optimized!')\n",
    "\n",
    "transforms = ['remove_nodes(op=Identity)', \n",
    "              'merge_duplicate_nodes',\n",
    "              'strip_unused_nodes',\n",
    "              'fold_constants(ignore_errors=true)',\n",
    "              'fold_batch_norms']#,\n",
    "              #'quantize_nodes',\n",
    "              #'quantize_weights']\n",
    "\n",
    "saved_model_dir = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization'\n",
    "optimize_graph(saved_model_dir, 'frozen_model.pb' , transforms, 'Conv2D_18/BiasAdd')\n",
    "optimized_filepath = os.path.join(saved_model_dir,'optimized_model.pb')\n",
    "#get_size(optimized_filepath)\n",
    "describe_graph(get_graph_def_from_file(optimized_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization_opt/saved_model.pb\n",
      "Optimized graph converted to SavedModel!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import importer\n",
    "\n",
    "def convert_graph_def_to_saved_model(export_dir, graph_filepath):\n",
    "    if tf.gfile.Exists(export_dir):\n",
    "        tf.gfile.DeleteRecursively(export_dir)\n",
    "    graph_def = get_graph_def_from_file(graph_filepath)\n",
    "    \n",
    "    with tf.Session(graph=tf.Graph()) as session:\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "        # save the model\n",
    "        builder = tf.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "\n",
    "        tensor_info_x = tf.saved_model.utils.build_tensor_info(x)\n",
    "        tensor_info_pred = tf.saved_model.utils.build_tensor_info(pred)\n",
    "\n",
    "        prediction_signature = (\n",
    "          tf.saved_model.signature_def_utils.build_signature_def(\n",
    "              inputs={'inputs/image': tensor_info_x},\n",
    "              outputs={'Conv2D_18/BiasAdd': tensor_info_pred},\n",
    "              method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "        builder.add_meta_graph_and_variables(\n",
    "          session, [tf.saved_model.tag_constants.SERVING],\n",
    "          signature_def_map={\n",
    "              tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
    "                  prediction_signature \n",
    "          },\n",
    "          strip_default_attrs=True,\n",
    "          )\n",
    "        saved_path = builder.save()\n",
    "    print('Optimized graph converted to SavedModel!')\n",
    "\n",
    "optimized_dir = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization_opt' \n",
    "optimized_filepath = os.path.join(saved_model_dir,'optimized_model.pb')\n",
    "convert_graph_def_to_saved_model(optimized_dir, optimized_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with tf.Session(graph=g) as sess:\n",
    "    loaded = tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], optimized_dir)\n",
    "    print(loaded)  # [\"serving_default\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize segmentation graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and convert the SavedModel into a GraphDef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation3/variables/variables\n"
     ]
    }
   ],
   "source": [
    "graph_def = get_graph_def_from_saved_model('/Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show graph description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Feature Nodes: ['inputs/image']\n",
      "\n",
      "Unused Nodes: []\n",
      "\n",
      "Output Nodes: ['Conv2D_18/BiasAdd']\n",
      "\n",
      "Quantization Nodes: []\n",
      "\n",
      "Constant Count: 132\n",
      "\n",
      "Variable Count: 38\n",
      "\n",
      "Identity Count: 44\n",
      " Total nodes: 619 \n"
     ]
    }
   ],
   "source": [
    "describe_graph(graph_def, show_nodes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation3/saved_model.pb \n",
      "Model size: 124.902 KB\n",
      "Variables size: 30650.242 KB\n",
      "Total Size: 30775.145 KB\n"
     ]
    }
   ],
   "source": [
    "get_size(f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation3',\n",
    "         model_file='saved_model.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] input_checkpoint: /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation/Unet.ckpt-20000\n",
      "INFO:tensorflow:Restoring parameters from /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation/Unet.ckpt-20000\n",
      "INFO:tensorflow:Froze 38 variables.\n",
      "INFO:tensorflow:Converted 38 variables to const ops.\n",
      "161 ops in the final graph.\n",
      "[INFO] output_graph: /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation/frozen_model.pb\n",
      "[INFO] all done\n",
      "Input Feature Nodes: ['inputs/image']\n",
      "\n",
      "Unused Nodes: []\n",
      "\n",
      "Output Nodes: ['Conv2D_18/BiasAdd']\n",
      "\n",
      "Quantization Nodes: []\n",
      "\n",
      "Constant Count: 50\n",
      "\n",
      "Variable Count: 0\n",
      "\n",
      "Identity Count: 38\n",
      " Total nodes: 161 \n"
     ]
    }
   ],
   "source": [
    "saved_model_dir = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation'\n",
    "frozen_filepath = os.path.join(saved_model_dir, 'frozen_model.pb')\n",
    "#freeze_model(saved_model_dir, 'Conv2D_18/BiasAdd', frozen_filepath, checkpoints=modelCkptSeg)\n",
    "freeze_model2(modelCkptSeg, frozen_filepath)\n",
    "frozen_filepath = os.path.join(saved_model_dir,'frozen_model.pb')\n",
    "#get_size(frozen_filepath)\n",
    "describe_graph(get_graph_def_from_file(frozen_filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization : pruning, constant folding and quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph optimized!\n",
      "Input Feature Nodes: ['inputs/image']\n",
      "\n",
      "Unused Nodes: []\n",
      "\n",
      "Output Nodes: ['Conv2D_18/BiasAdd']\n",
      "\n",
      "Quantization Nodes: []\n",
      "\n",
      "Constant Count: 44\n",
      "\n",
      "Variable Count: 0\n",
      "\n",
      "Identity Count: 0\n",
      " Total nodes: 117 \n"
     ]
    }
   ],
   "source": [
    "transforms = ['remove_nodes(op=Identity)', \n",
    "              'merge_duplicate_nodes',\n",
    "              'strip_unused_nodes',\n",
    "              'fold_constants(ignore_errors=true)',\n",
    "              'fold_batch_norms']\n",
    "\n",
    "optimize_graph(saved_model_dir, 'frozen_model.pb' , transforms, 'Conv2D_18/BiasAdd')\n",
    "optimized_filepath = os.path.join(saved_model_dir,'optimized_model.pb')\n",
    "#get_size(optimized_filepath)\n",
    "describe_graph(get_graph_def_from_file(optimized_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/sebastientourbier/Softwares/mialsuperresolutiontoolkit/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation_opt/saved_model.pb\n",
      "Optimized graph converted to SavedModel!\n"
     ]
    }
   ],
   "source": [
    "optimized_dir = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation_opt' \n",
    "optimized_filepath = os.path.join(saved_model_dir,'optimized_model.pb')\n",
    "convert_graph_def_to_saved_model(optimized_dir, optimized_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create interface prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymialsrtk.interfaces.preprocess import BrainExtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainExtraction2(BrainExtraction):\n",
    "    # Redefine _extract_brain()\n",
    "    def _extractBrain(self, dataPath, modelCkptLoc, thresholdLoc, modelCkptSeg, thresholdSeg, bidsDir, out_postfix):\n",
    "        \"\"\"Generate a brain mask by passing the input image(s) through two networks.\n",
    "\n",
    "        The first network localizes the brain by a coarse-grained segmentation while the\n",
    "        second one segments it more precisely. The function saves the output mask in the\n",
    "        specific module folder created in bidsDir\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataPath <string>\n",
    "            Input image file (required)\n",
    "\n",
    "        modelCkptLoc <string>\n",
    "            Network_checkpoint for localization (required)\n",
    "\n",
    "        thresholdLoc <Float>\n",
    "             Threshold determining cutoff probability (default is 0.49)\n",
    "\n",
    "        modelCkptSeg <string>\n",
    "            Network_checkpoint for segmentation\n",
    "\n",
    "        thresholdSeg <Float>\n",
    "             Threshold determining cutoff probability (default is 0.5)\n",
    "\n",
    "        bidsDir <string>\n",
    "            BIDS root directory (required)\n",
    "\n",
    "        out_postfix <string>\n",
    "            Suffix of the automatically generated mask (default is '_brainMask.nii.gz')\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        ##### Step 1: Brain localization #####\n",
    "        normalize = \"local_max\"\n",
    "        width = 128\n",
    "        height = 128\n",
    "        border_x = 15\n",
    "        border_y = 15\n",
    "        n_channels = 1\n",
    "\n",
    "        img_nib = nibabel.load(os.path.join(dataPath))\n",
    "        image_data = img_nib.get_data()\n",
    "        images = np.zeros((image_data.shape[2], width, height, n_channels))\n",
    "        pred3dFinal = np.zeros((image_data.shape[2], image_data.shape[0], image_data.shape[1], n_channels))\n",
    "\n",
    "        slice_counter = 0\n",
    "        for ii in range(image_data.shape[2]):\n",
    "            img_patch = cv2.resize(image_data[:, :, ii], dsize=(width, height), fx=width,\n",
    "                                   fy=height)\n",
    "\n",
    "            if normalize:\n",
    "                if normalize == \"local_max\":\n",
    "                    images[slice_counter, :, :, 0] = img_patch / np.max(img_patch)\n",
    "                elif normalize == \"global_max\":\n",
    "                    images[slice_counter, :, :, 0] = img_patch / max_val\n",
    "                elif normalize == \"mean_std\":\n",
    "                    images[slice_counter, :, :, 0] = (img_patch-np.mean(img_patch))/np.std(img_patch)\n",
    "                else:\n",
    "                    raise ValueError('Please select a valid normalization')\n",
    "            else:\n",
    "                images[slice_counter, :, :, 0] = img_patch\n",
    "\n",
    "            slice_counter += 1\n",
    "\n",
    "        # Thresholding parameter to binarize predictions\n",
    "        percentileLoc = thresholdLoc*100\n",
    "\n",
    "        im = np.zeros((1, width, height, n_channels))\n",
    "        pred3d = []\n",
    "        # Create a clean graph and import the MetaGraphDef nodes.\n",
    "        g = tf.Graph()\n",
    "        with tf.Session(graph=g) as sess_test_loc:\n",
    "            signature_key = tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "            input_key = 'inputs/image'\n",
    "            output_key = 'Conv2D_18/BiasAdd'\n",
    "            # Restore the model\n",
    "            meta_graph_def = tf.saved_model.loader.load(sess_test_loc,\n",
    "                                                        [tf.saved_model.tag_constants.SERVING],\n",
    "                                                        modelCkptLoc)\n",
    "            \n",
    "            signature = meta_graph_def.signature_def\n",
    "            \n",
    "            x_tensor_name = signature[signature_key].inputs[input_key].name\n",
    "            pred_tensor_name = signature[signature_key].outputs[output_key].name\n",
    "\n",
    "            x = sess_test_loc.graph.get_tensor_by_name(x_tensor_name)\n",
    "            pred = sess_test_loc.graph.get_tensor_by_name(pred_tensor_name)\n",
    "\n",
    "            for idx in range(images.shape[0]):\n",
    "\n",
    "                im = np.reshape(images[idx, :, :, :], [1, width, height, n_channels])\n",
    "                print(im.shape)\n",
    "                feed_dict = {x: im}\n",
    "                pred_ = sess_test_loc.run(pred, feed_dict=feed_dict)\n",
    "\n",
    "                theta = np.percentile(pred_, percentileLoc)\n",
    "                pred_bin = np.where(pred_ > theta, 1, 0)\n",
    "                pred3d.append(pred_bin[0, :, :, 0].astype('float64'))\n",
    "\n",
    "            #####\n",
    "            pred3d = np.asarray(pred3d)\n",
    "            heights = []\n",
    "            widths = []\n",
    "            coms_x = []\n",
    "            coms_y = []\n",
    "\n",
    "            # Apply PPP\n",
    "            ppp = True\n",
    "            if ppp:\n",
    "                pred3d = self._post_processing(pred3d)\n",
    "\n",
    "            pred3d = [cv2.resize(elem,dsize=(image_data.shape[1], image_data.shape[0]), interpolation=cv2.INTER_NEAREST) for elem in pred3d]\n",
    "            pred3d = np.asarray(pred3d)\n",
    "            for i in range(np.asarray(pred3d).shape[0]):\n",
    "                if np.sum(pred3d[i, :, :]) != 0:\n",
    "                    pred3d[i, :, :] = self._extractLargestCC(pred3d[i, :, :].astype('uint8'))\n",
    "                    contours, _ = cv2.findContours(pred3d[i, :, :].astype('uint8'), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    area = cv2.minAreaRect(np.squeeze(contours))\n",
    "                    heights.append(area[1][0])\n",
    "                    widths.append(area[1][1])\n",
    "                    bbox = cv2.boxPoints(area).astype('int')\n",
    "                    coms_x.append(int((np.max(bbox[:, 1])+np.min(bbox[:, 1]))/2))\n",
    "                    coms_y.append(int((np.max(bbox[:, 0])+np.min(bbox[:, 0]))/2))\n",
    "            # Saving localization points\n",
    "            med_x = int(np.median(coms_x))\n",
    "            med_y = int(np.median(coms_y))\n",
    "            half_max_x = int(np.max(heights)/2)\n",
    "            half_max_y = int(np.max(widths)/2)\n",
    "            x_beg = med_x-half_max_x-border_x\n",
    "            x_end = med_x+half_max_x+border_x\n",
    "            y_beg = med_y-half_max_y-border_y\n",
    "            y_end = med_y+half_max_y+border_y\n",
    "\n",
    "        ##### Step 2: Brain segmentation #####\n",
    "        width = 96\n",
    "        height = 96\n",
    "\n",
    "        images = np.zeros((image_data.shape[2], width, height, n_channels))\n",
    "\n",
    "        slice_counter = 0\n",
    "        for ii in range(image_data.shape[2]):\n",
    "            img_patch = cv2.resize(image_data[x_beg:x_end, y_beg:y_end, ii], dsize=(width, height))\n",
    "\n",
    "            if normalize:\n",
    "                if normalize == \"local_max\":\n",
    "                    images[slice_counter, :, :, 0] = img_patch / np.max(img_patch)\n",
    "                elif normalize == \"mean_std\":\n",
    "                    images[slice_counter, :, :, 0] = (img_patch-np.mean(img_patch))/np.std(img_patch)\n",
    "                else:\n",
    "                    raise ValueError('Please select a valid normalization')\n",
    "            else:\n",
    "                images[slice_counter, :, :, 0] = img_patch\n",
    "\n",
    "            slice_counter += 1\n",
    "\n",
    "        g = tf.Graph()\n",
    "        with tf.Session(graph=g) as sess_test_seg:\n",
    "            signature_key = tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "            input_key = 'inputs/image'\n",
    "            output_key = 'Conv2D_18/BiasAdd'\n",
    "            # Restore the model\n",
    "            meta_graph_def = tf.saved_model.loader.load(sess_test_seg,\n",
    "                                                        [tf.saved_model.tag_constants.SERVING],\n",
    "                                                        modelCkptSeg)\n",
    "            \n",
    "            signature = meta_graph_def.signature_def\n",
    "            \n",
    "            x_tensor_name = signature[signature_key].inputs[input_key].name\n",
    "            pred_tensor_name = signature[signature_key].outputs[output_key].name\n",
    "\n",
    "            x = sess_test_seg.graph.get_tensor_by_name(x_tensor_name)\n",
    "            pred = sess_test_seg.graph.get_tensor_by_name(pred_tensor_name)\n",
    "\n",
    "            for idx in range(images.shape[0]):\n",
    "\n",
    "                im = np.reshape(images[idx, :, :], [1, width, height, n_channels])\n",
    "                feed_dict = {x: im}\n",
    "                pred_ = sess_test_seg.run(pred, feed_dict=feed_dict)\n",
    "                percentileSeg = thresholdSeg * 100\n",
    "                theta = np.percentile(pred_, percentileSeg)\n",
    "                pred_bin = np.where(pred_ > theta, 1, 0)\n",
    "                # Map predictions to original indices and size\n",
    "                pred_bin = cv2.resize(pred_bin[0, :, :, 0], dsize=(y_end-y_beg, x_end-x_beg), interpolation=cv2.INTER_NEAREST)\n",
    "                pred3dFinal[idx, x_beg:x_end, y_beg:y_end,0] = pred_bin.astype('float64')\n",
    "\n",
    "            pppp = True\n",
    "            if pppp:\n",
    "                pred3dFinal = self._post_processing(np.asarray(pred3dFinal))\n",
    "            pred3d = [cv2.resize(elem, dsize=(image_data.shape[1], image_data.shape[0]), interpolation=cv2.INTER_NEAREST) for elem in pred3dFinal]\n",
    "            pred3d = np.asarray(pred3d)\n",
    "            upsampled = np.swapaxes(np.swapaxes(pred3d,1,2),0,2) #if Orient module applied, no need for this line(?)\n",
    "            up_mask = nibabel.Nifti1Image(upsampled,img_nib.affine)\n",
    "            # Save output mask\n",
    "\n",
    "            _, name, ext = split_filename(os.path.abspath(dataPath))\n",
    "            save_file = os.path.join(os.getcwd(), ''.join((name, out_postfix, ext)))\n",
    "            nibabel.save(up_mask, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201205-11:35:35,937 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"brainmask2_wf_node\" in \"/Users/sebastientourbier/Desktop/mialsrtk/brainmask2_wf_node\".\n",
      "201205-11:35:35,943 nipype.workflow INFO:\n",
      "\t [Node] Running \"brainmask2_wf_node\" (\"__main__.BrainExtraction2\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/envs/pymialsrtk-env/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Failed\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/miniconda3/envs/pymialsrtk-env/lib/python3.6/site-packages/pymialsrtk/interfaces/preprocess.py\", line 1542, in _run_interface\n",
      "    self.inputs.in_ckpt_seg, self.inputs.threshold_seg, self.inputs.bids_dir, self.inputs.out_postfix)\n",
      "  File \"<ipython-input-47-66cfb763983a>\", line 180, in _extractBrain\n",
      "    pred_ = sess_test_seg.run(pred, feed_dict=feed_dict)\n",
      "  File \"/Applications/miniconda3/envs/pymialsrtk-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/Applications/miniconda3/envs/pymialsrtk-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1128, in _run\n",
      "    str(subfeed_t.get_shape())))\n",
      "ValueError: Cannot feed value of shape (1, 96, 96, 1) for Tensor 'inputs/image:0', which has shape '(?, 128, 128, 1)'\n",
      "\n",
      "201205-11:35:38,792 nipype.workflow INFO:\n",
      "\t [Node] Finished \"brainmask2_wf_node\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nipype.interfaces.base.support.InterfaceResult at 0x7fc583f9cd68>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nipype import Node\n",
    "import cv2\n",
    "import skimage.measure\n",
    "\n",
    "import scipy.ndimage as snd\n",
    "from skimage import morphology\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "import nibabel\n",
    "import numpy as np\n",
    "\n",
    "brainmask = Node(interface=BrainExtraction2(),\n",
    "                 name='brainmask2_wf_node',\n",
    "                 base_dir = '/Users/sebastientourbier/Desktop/mialsrtk')\n",
    "brainmask.inputs.bids_dir = f'{toolkit_dir}/data'\n",
    "brainmask.inputs.in_file = image\n",
    "brainmask.inputs.in_ckpt_loc = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_localization_opt'\n",
    "brainmask.inputs.threshold_loc = 0.49\n",
    "brainmask.inputs.in_ckpt_seg = f'{toolkit_dir}/pymialsrtk/data/Network_checkpoints/Network_checkpoints_segmentation_opt'\n",
    "brainmask.inputs.threshold_seg = 0.5\n",
    "brainmask.inputs.out_postfix = '_brainMask2.nii.gz'\n",
    "brainmask.run() # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seems challenging to load frozen graph generated from TFLEARN. Should we also describe all inputs to layers? The error above might suggest so.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
